# This file contains all of the hub's available properties
# Please refer to https://flightstats.github.io/hub/hub_install_locally.html for more details
# optional - defaults to aws
# aws means the Hub will use S3, Dynamo and Spoke.  You must set all of the AWS settings for this to work
# test means the Hub has no AWS dependencies
hub.type=test
# app.name is used:
# with app.environment for creating a zookeeper name space
# with app.environment for creating Dynamo table names
# with app.environment for publishing metrics
# with s3.environment for the S3 bucket
app.name=hub
# A logical name for your environment, dev, staging, prod, etc
app.environment=single
# app.url is the load balanced url.  It is used during replication, batching and alerts.
app.url=http://localhost/
# Change the maximum multipart payload size
app.maxPayloadSizeMB=40
# Set what size payload constitutes "large"
app.large.payload.MB=10000
# The hub reads it's version number from the gradle built library file in this folder
app.lib_path=/opt/hub/lib
# full path to Spoke's folder
spoke.path=/mnt/spoke
# spoke TTL enforcement is time based, deleting all files older than spoke.ttlMinutes
spoke.enforceTTL=false
spoke.ttlMinutes=60
# For test systems, enforce the TTL based on each channel's ttlDays
channel.enforceTTL=true
# Storage path is used to store Channels and Webhooks outside of DynamoDB
storage.path=/tmp/storage
#Set this to true to protect channels.  The default is true.  Non-production environments will want this false.
hub.protect.channels=false
#How long an http request needs to take before being considered 'slow' and logged
logSlowTracesSeconds=10
# The maximum size of traces to limit memory pressure.  Increase this to see more information
traces.limit=50
# Should the hub process alerts?
alert.run=true
# Time to sleep between alert checks
#alert.sleep.millis=60000
# Name of the channel to store alert configurations
#alert.channel.config=zomboAlertsConfig
# Name of the channel to store triggered alerts
#alert.channel.escalate=escalationAlerts
# change if you want to use a different internal port
http.bind_port=80
# The latency from 'now' for items to be considered stable.
app.stable_seconds=2
# Enable this to adjust timing for a hub cluster.  This supports the single threaded writer use case.
app.runNtpMonitor=false
# When using app.runNtpMonitor, this is the minium coordination threshold for the time difference in a cluster
#app.minPostTimeMillis=5
# This is the maximum delay
#app.maxPostTimeMillis=1000
#This is the time of the oldest live item in a hub.  With the exception of historical, we know not to query before
# this time.
#app.birthDay=2015/01/01
# Enable DataDog metrics
metrics.enable=false
# Enable Hosted Graphite metrics
hosted_graphite.enable=false
#hosted_graphite.host=carbon.hostedgraphite.com
#hosted_graphite.port=2003
#hosted_graphite.apikey=YourAPIKey
# How frequently to publish internal metrics
metrics.seconds=30
metrics.influxdb.database.name=hub_tick
metrics.influxdb.host=localhost
# metrics.influxdb.database.password=<password>
metrics.influxdb.port=8086
metrics.influxdb.protocol=http
# metrics.influxdb.database.user=username
metrics.tags.role=hub
metrics.tags.team=development
# Maximum number of items to allow in a directional query (next, previous, earliest and latest)
#app.directionCountLimit=10000
# optional - set this to HTTPS if you have sensitive data
#aws.protocol=HTTP
# Production quality hub environments use a proactive GC strategy to reduce memory pressure
#hub.gcMinutes=5
#hub.runGC=false
# For a graceful shutdown, wait up to shutdown_wait_seconds for all incoming Posts to complete
# This prevents 503s from the load balancer during rolling restarts
#app.shutdown_wait_seconds=5
# Wait shutdown_delay_seconds for the hub to be removed from the load balancer during shutdown
#app.shutdown_delay_seconds=5
# http.bind_port=8080
# optional - idle timeout for jetty connections
# http.idle_timeout=30000
# optional - bind ip address
# http.bind_ip=0.0.0.0
# http.idle_timeout=30000
# Conncetion settings for the hub making htpp connections for Spoke, etc
http.connect.timeout.seconds=30
http.read.timeout.seconds=120
http.maxRetries=8
#Exponential factor for retries
http.sleep=1000
# zookeeper.connection where does ZooKeeper live?
zookeeper.connection=localhost:2181
# for running the hub on a single machine, run ZooKeeper in process with the hub
runSingleZookeeperInternally=singleNode
# Zookeeper connection settings
#zookeeper.baseSleepTimeMs=10
#zookeeper.maxSleepTimeMs=10000
#zookeeper.maxRetries=20
# Number of threads to process ZooKeeper Watch events
#watchManager.threads=10
# optional Use encryption in flight and at rest
#app.encrypted=false
# Full Path to jks certificates for the encryoted hub
#app.keyStorePath=/full/path/cert.jks
# Full Path to key for the encryoted hub
#app.keyStorePasswordPath=/etc/ssl/key
#############################
# AWS Settings
#############################
# If you are running the hub in EC2, the hub will automatically pick up the credentials provided by the IAM role
# If not running in EC2, specify credentials is this file with secretKey and accessKey
#aws.credentials=/full/path/to/file
# Where is your dynamo? http://docs.aws.amazon.com/general/latest/gr/rande.html#ddb_region
#dynamo.endpoint=dynamodb.us-east-1.amazonaws.com
# Throughput settings for dynamo tables
#dynamo.throughput.channel.read=100
#dynamo.throughput.channel.write=10
#dynamo.throughput.webhook.read=100
#dynamo.throughput.webhook.write=10
#dynamo.maxConnections=50
#dynamo.connectionTimeout=10000
#dynamo.socketTimeout=30000
# optional how long to wait for a dynamo db table to be created
# dynamo.table_creation_wait_minutes=10
#where is your S3 bucket? http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region
#s3.endpoint=s3-external-1.amazonaws.com
# is used to create the s3 bucket name {app.name}-{s3.environment}
#s3.environment=east1
#s3.maxConnections=50
#s3.connectionTimeout=10000
#s3.socketTimeout=30000
# optional maximum items in the S3 write behind queue
# s3.writeQueueSize=2000
# optional max threads for the S3 write behind queue
# s3.writeQueueThreads=20
# This is used in test environments to make sure that our S3 verification process works
#s3.dropSomeWrites=false
# How frequently to run S3 verification process
#s3Verifier.offsetMinutes=15
# Number of threads to process at one time, used to throttle impact
#s3Verifier.channelThreads=3
